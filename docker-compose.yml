services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - NVIDIA_DRIVER_CAPABILITIES=all
      - LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu
      - PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      - OLLAMA_ORIGINS=*
      # Критично для GPU
      - OLLAMA_GPU_LAYERS=999
      - OLLAMA_NUM_GPU=1
      # Оптимізація для 4GB VRAM (GTX 1050 Ti)
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-30s}
      - OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL:-1}
      - OLLAMA_NUM_THREADS=${OLLAMA_NUM_THREADS:-4}
      - OMP_NUM_THREADS=${OMP_NUM_THREADS:-4}
      - OPENBLAS_NUM_THREADS=${OPENBLAS_NUM_THREADS:-4}
      # З оригіналу
      - OLLAMA_USE_GPU=${OLLAMA_USE_GPU:-true}
      - OLLAMA_PREFERRED_GPU_NAME=${OLLAMA_PREFERRED_GPU_NAME:-NVIDIA GeForce GTX 1050 Ti}
    entrypoint: ["/usr/local/bin/ollama-select-gpu.sh"]
    command: ["serve"]
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 10s
    volumes:
      - ollama:/root/.ollama
      - ./scripts/ollama-select-gpu.sh:/usr/local/bin/ollama-select-gpu.sh:ro
    privileged: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: ${NVIDIA_GPU_COUNT:-1}
              capabilities: [gpu]

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    platform: linux/amd64
    depends_on:
      ollama:
        condition: service_healthy
    security_opt:
      - seccomp=unconfined
      - apparmor=unconfined
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_API_BASE_URL=http://ollama:11434
      - RAG_EMBEDDING_ENGINE=ollama
      - RAG_EMBEDDING_MODEL=nomic-embed-text
      - ENABLE_RAG_WEB_SEARCH=true
      - RAG_EMBEDDING_MODEL_AUTO_UPDATE=false
      - WHISPER_MODEL=base
      - WHISPER_MODEL_AUTO_UPDATE=false
      - OLLAMA_NUM_PARALLEL=1
      - UVICORN_LOOP=asyncio
    ports:
      - "3000:8080"
    volumes:
      - openwebui:/app/backend/data

  proxmox-controller:
    build:
      context: .
      args:
        INSTALL_GPU_EXTRAS: ${INSTALL_GPU_EXTRAS:-false}
    container_name: proxmox-controller
    restart: unless-stopped
    depends_on: [ollama]
    security_opt:
      - seccomp=unconfined
      - apparmor=unconfined
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - PROXMOX_HOST=${PROXMOX_HOST}
      - PROXMOX_PORT=${PROXMOX_PORT:-8006}
      - PROXMOX_USER=${PROXMOX_USER}
      - PROXMOX_TOKEN_NAME=${PROXMOX_TOKEN_NAME}
      - PROXMOX_TOKEN_VALUE=${PROXMOX_TOKEN_VALUE}
      - PROXMOX_VERIFY_SSL=${PROXMOX_VERIFY_SSL:-False}
      - CORS_ALLOW_ORIGINS=${CORS_ALLOW_ORIGINS:-*}
      - PVE_SSH_HOST=${PVE_SSH_HOST}
      - PVE_SSH_USER=${PVE_SSH_USER:-root}
      - PVE_SSH_KEY_PATH=/keys/pve_id_rsa
      - BLISS_ADB_ADDRESS=${BLISS_ADB_ADDRESS:-}
      - BLISS_ADB_HOST=${BLISS_ADB_HOST:-}
      - BLISS_ADB_PORT=${BLISS_ADB_PORT:-5555}
      - BLISS_ADB_SERIAL=${BLISS_ADB_SERIAL:-}
      - ADB_BINARY=${ADB_BINARY:-}
      - BLISS_OPENAPI_PATH=${BLISS_OPENAPI_PATH:-}
      - UVICORN_LOOP=asyncio
    volumes:
      - ./keys:/keys:ro
      - ./openapi.json:/app/openapi.json:ro
      - ./openapi_bliss.json:/app/openapi_bliss.json:ro
    command: ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000", "--loop", "asyncio"]
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 10s

volumes:
  ollama:
  openwebui:
