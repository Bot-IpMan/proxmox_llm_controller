services:
  openai-edge-tts:
    image: travisvn/openai-edge-tts:latest
    container_name: openai-edge-tts
    ports:
      - "5050:5050"
    restart: unless-stopped

  ollama:
    image: ollama/ollama:0.12.3
    container_name: ollama
    restart: unless-stopped
    ports: ["11434:11434"]

    # ✅ ОФІЦІЙНИЙ спосіб дати GPU в Compose
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]         # або count: 1
              capabilities: [gpu]       # обов'язково!

    environment:
      # Примусово увімкнути CUDA-бекенд у Ollama
      - OLLAMA_LLM_LIBRARY=cuda
      # Ліміт паралельності скромний, щоб не впертись у VRAM 4 ГБ
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_KEEP_ALIVE=10s
      - OLLAMA_KV_CACHE_TYPE=f16
      # Явно вкажемо видиму карту (деякі середовища це потребують)
      - NVIDIA_VISIBLE_DEVICES=0
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      # FlashAttention на Pascal не допомагає — вимикаємо
      - OLLAMA_FLASH_ATTENTION=false

    # Послаблюємо профілі безпеки — це усуває 304 у частини систем
    security_opt:
      - seccomp=unconfined
      - apparmor=unconfined
    privileged: true

    volumes:
      - ollama:/root/.ollama

    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 40s

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    depends_on:
      ollama:
        condition: service_healthy
      openai-edge-tts:
        condition: service_started
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_API_BASE_URL=http://ollama:11434
      - RAG_EMBEDDING_ENGINE=ollama
      - RAG_EMBEDDING_MODEL=nomic-embed-text
      - ENABLE_RAG_WEB_SEARCH=true
      - RAG_EMBEDDING_MODEL_AUTO_UPDATE=false
      - WHISPER_MODEL=base
      - WHISPER_MODEL_AUTO_UPDATE=false
      - OLLAMA_NUM_PARALLEL=1
      - UVICORN_LOOP=asyncio
      - AUDIO_TTS_ENGINE=openai
      - AUDIO_TTS_OPENAI_API_BASE_URL=http://openai-edge-tts:5050/v1
      - AUDIO_TTS_OPENAI_API_KEY=anything
      - AUDIO_TTS_MODEL=tts-1
      - AUDIO_TTS_VOICE=uk-UA-PolinaNeural
      - AUDIO_TTS_SPLIT_ON=punctuation
    security_opt:
      - seccomp=unconfined
      - apparmor=unconfined
    ulimits:
      nofile: 65536
    ports:
      - "3000:8080"
    volumes:
      - openwebui:/app/backend/data

  proxmox-controller:
    build:
      context: .
      args:
        INSTALL_GPU_EXTRAS: ${INSTALL_GPU_EXTRAS:-false}
    container_name: proxmox-controller
    restart: unless-stopped
    depends_on:
      - ollama
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - PROXMOX_HOST=${PROXMOX_HOST}
      - PROXMOX_PORT=${PROXMOX_PORT:-8006}
      - PROXMOX_USER=${PROXMOX_USER}
      - PROXMOX_TOKEN_NAME=${PROXMOX_TOKEN_NAME}
      - PROXMOX_TOKEN_VALUE=${PROXMOX_TOKEN_VALUE}
      - PROXMOX_VERIFY_SSL=${PROXMOX_VERIFY_SSL:-False}
      - CORS_ALLOW_ORIGINS=${CORS_ALLOW_ORIGINS:-*}
      - PVE_SSH_HOST=${PVE_SSH_HOST}
      - PVE_SSH_USER=${PVE_SSH_USER:-root}
      - PVE_SSH_KEY_PATH=/keys/pve_id_rsa
      - UVICORN_LOOP=asyncio
    security_opt:
      - seccomp=unconfined
      - apparmor=unconfined
    command: ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000", "--loop", "asyncio"]
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 10s
    volumes:
      - ./keys:/keys:ro
      - ./openapi.json:/app/openapi.json:ro
      - ./openapi_bliss.json:/app/openapi_bliss.json:ro

  # Додатковий сервіс для швидкої перевірки GPU через Compose
  gpu-test:
    image: nvidia/cuda:12.9.0-base-ubuntu22.04
    command: ["bash", "-lc", "nvidia-smi && ls -l /dev/nvidia* || true"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  ollama:
  openwebui:
